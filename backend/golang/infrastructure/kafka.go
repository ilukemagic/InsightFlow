package infrastructure

import (
	"encoding/json"
	"log"

	"insightflow/models"

	"github.com/Shopify/sarama"
)

// KafkaProducer Kafkaç”Ÿäº§è€…åŒ…è£…
// Topicå’ŒPartitionçš„å…³ç³»ï¼š
// - Topicæ˜¯é€»è¾‘æ¦‚å¿µï¼Œç±»ä¼¼æ•°æ®åº“çš„"è¡¨"
// - Partitionæ˜¯ç‰©ç†æ¦‚å¿µï¼Œç±»ä¼¼æ•°æ®åº“è¡¨çš„"åˆ†ç‰‡"
// - ä¸€ä¸ªTopicå¯ä»¥åŒ…å«å¤šä¸ªPartitionï¼Œç”¨äºå¹¶è¡Œå¤„ç†å’Œè´Ÿè½½åˆ†å¸ƒ
type KafkaProducer struct {
	producer sarama.SyncProducer
	topic    string
}

// NewKafkaProducer åˆ›å»ºKafkaç”Ÿäº§è€…
// å½“å‰é…ç½®ï¼šé»˜è®¤åˆ†åŒºç­–ç•¥ï¼Œé€‚åˆä¸­å°å‹é¡¹ç›®
// åˆ†åŒºè¯´æ˜ï¼š
// - å¦‚æœtopicåªæœ‰1ä¸ªåˆ†åŒºï¼Œæ‰€æœ‰æ¶ˆæ¯ä¸²è¡Œå¤„ç†ï¼Œä¿è¯å…¨å±€é¡ºåº
// - å¦‚æœtopicæœ‰å¤šä¸ªåˆ†åŒºï¼Œç›¸åŒkeyçš„æ¶ˆæ¯ä¼šåˆ°åŒä¸€åˆ†åŒºï¼Œä¿è¯å±€éƒ¨é¡ºåº
func NewKafkaProducer(brokers []string, topic string) (*KafkaProducer, error) {
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true
	config.Producer.Retry.Max = 3
	config.Producer.RequiredAcks = sarama.WaitForAll

	// åˆ†åŒºç­–ç•¥ï¼šé»˜è®¤æ˜¯Hashåˆ†åŒºå™¨
	// - æœ‰keyæ—¶ï¼šç›¸åŒkeyçš„æ¶ˆæ¯æ€»æ˜¯å‘åˆ°åŒä¸€åˆ†åŒºï¼ˆä¿è¯ç”¨æˆ·äº‹ä»¶é¡ºåºï¼‰
	// - æ— keyæ—¶ï¼šè½®è¯¢å‘é€åˆ°å„ä¸ªåˆ†åŒºï¼ˆè´Ÿè½½å‡è¡¡ï¼‰

	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		return nil, err
	}

	return &KafkaProducer{
		producer: producer,
		topic:    topic,
	}, nil
}

// SendEvent å‘é€äº‹ä»¶åˆ°Kafka
// ä½¿ç”¨UserIDä½œä¸ºåˆ†åŒºkeyï¼Œç¡®ä¿åŒä¸€ç”¨æˆ·çš„äº‹ä»¶æŒ‰é¡ºåºå¤„ç†
func (kp *KafkaProducer) SendEvent(event models.UserEvent) error {
	eventJSON, err := json.Marshal(event)
	if err != nil {
		return err
	}

	message := &sarama.ProducerMessage{
		Topic: kp.topic,
		Key:   sarama.StringEncoder(event.UserID), // åˆ†åŒºkeyï¼šåŒä¸€ç”¨æˆ·åˆ°åŒä¸€åˆ†åŒº
		Value: sarama.ByteEncoder(eventJSON),
	}

	partition, offset, err := kp.producer.SendMessage(message)
	if err != nil {
		return err
	}

	// å¯é€‰ï¼šæ‰“å°åˆ†åŒºä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
	log.Printf("äº‹ä»¶å‘é€æˆåŠŸ: Topic=%s, Partition=%d, Offset=%d, UserID=%s",
		kp.topic, partition, offset, event.UserID)

	return nil
}

// Close å…³é—­ç”Ÿäº§è€…
func (kp *KafkaProducer) Close() error {
	return kp.producer.Close()
}

// KafkaConsumer Kafkaæ¶ˆè´¹è€…åŒ…è£…
// Consumerè‡ªåŠ¨æ¶ˆè´¹æ‰€æœ‰åˆ†åŒºçš„æ¶ˆæ¯
type KafkaConsumer struct {
	consumer sarama.Consumer
	topic    string
}

// NewKafkaConsumer åˆ›å»ºKafkaæ¶ˆè´¹è€…
func NewKafkaConsumer(brokers []string, topic string) (*KafkaConsumer, error) {
	config := sarama.NewConfig()
	config.Consumer.Return.Errors = true
	config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin

	consumer, err := sarama.NewConsumer(brokers, config)
	if err != nil {
		return nil, err
	}

	return &KafkaConsumer{
		consumer: consumer,
		topic:    topic,
	}, nil
}

// Start å¯åŠ¨æ¶ˆè´¹è€…
// è‡ªåŠ¨æ£€æµ‹åˆ†åŒºæ•°é‡å¹¶å¹¶è¡Œæ¶ˆè´¹æ‰€æœ‰åˆ†åŒº
func (kc *KafkaConsumer) Start(eventHandler func(models.UserEvent)) error {
	// è·å–topicçš„æ‰€æœ‰åˆ†åŒº
	partitions, err := kc.consumer.Partitions(kc.topic)
	if err != nil {
		return err
	}

	log.Printf("ğŸ¯ Kafkaæ¶ˆè´¹è€…å·²å¯åŠ¨: Topic=%s, åˆ†åŒºæ•°é‡=%d", kc.topic, len(partitions))

	// ä¸ºæ¯ä¸ªåˆ†åŒºå¯åŠ¨ä¸€ä¸ªgoroutineå¹¶è¡Œæ¶ˆè´¹
	for _, partition := range partitions {
		go func(partitionID int32) {
			partitionConsumer, err := kc.consumer.ConsumePartition(kc.topic, partitionID, sarama.OffsetNewest)
			if err != nil {
				log.Printf("å¯åŠ¨åˆ†åŒº %d æ¶ˆè´¹è€…å¤±è´¥: %v", partitionID, err)
				return
			}
			defer partitionConsumer.Close()

			log.Printf("å¼€å§‹æ¶ˆè´¹åˆ†åŒº: %d", partitionID)

			// å¤„ç†è¯¥åˆ†åŒºçš„æ¶ˆæ¯
			for {
				select {
				case message := <-partitionConsumer.Messages():
					var event models.UserEvent
					if err := json.Unmarshal(message.Value, &event); err != nil {
						log.Printf("è§£æKafkaæ¶ˆæ¯å¤±è´¥: %v", err)
						continue
					}

					log.Printf("æ¥æ”¶æ¶ˆæ¯: Partition=%d, Offset=%d, UserID=%s",
						message.Partition, message.Offset, event.UserID)

					// å¤„ç†äº‹ä»¶
					go eventHandler(event)

				case err := <-partitionConsumer.Errors():
					log.Printf("åˆ†åŒº %d æ¶ˆè´¹é”™è¯¯: %v", partitionID, err)
				}
			}
		}(partition)
	}

	return nil
}

// Close å…³é—­æ¶ˆè´¹è€…
func (kc *KafkaConsumer) Close() error {
	return kc.consumer.Close()
}
